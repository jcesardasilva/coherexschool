{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TBFXQGKYUc4X"
   },
   "source": [
    "# Tutorial on Image Classification without Image Augmentation\n",
    "\n",
    "### Tutor: Julio C. da Silva (Néel Institute CNRS, Grenoble, France) /  email: julio-cesar.da-silva@neel.cnrs.fr\n",
    "#### Personal webpage: https://sites.google.com/view/jcesardasilva\n",
    "\n",
    "Disclaimer: This notebook is intended for educational reasons only and should not be used for professional data analysis. For the latter, other, more efficient, and complete codes are available. It is essential to mention that the Python codes were inspired by the \"Tutorial TensorFlow\" provided by TensorFlow Core by TensorFlow authors. Modifications have been made to the original code for educational reasons and Python compatibility. Further information and other tutorials are available at: https://www.tensorflow.org/tutorials\n",
    "\n",
    "This code run in **Python3** and requires certain python packages, which are: **Numpy, IPython, Matplotlib, Scikit-Image, Tensorflow, Keras**\n",
    "\n",
    "If you do not have those packages, I suggest their installation via pip install: \n",
    "\n",
    "    pip3 install numpy, ipython, matplotlib, scikit-image, tensorflow, keras\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gN7G9GFmVrVY"
   },
   "source": [
    "In this tutorial, we will discuss how to classify images into pictures of cats or pictures of dogs. We'll build an image classifier using `tf.keras.Sequential` model and load data using `tf.keras.preprocessing.image.ImageDataGenerator`.\n",
    "\n",
    "## Specific concepts that will be covered:\n",
    "In the process, we will build practical experience and develop intuition around the following concepts\n",
    "\n",
    "* Building _data input pipelines_ using the `tf.keras.preprocessing.image.ImageDataGenerator` class — How can we efficiently work with data on disk to interface with our model?\n",
    "* _Overfitting_ - what is it, how to identify it?\n",
    "\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zF9uvbXNVrVY"
   },
   "source": [
    "# Importing packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VddxeYBEVrVZ"
   },
   "source": [
    "Let's start by importing required packages:\n",
    "\n",
    "*   os — to read files and directory structure\n",
    "*   numpy — for some matrix math outside of TensorFlow\n",
    "*   matplotlib.pyplot — to plot the graph and display images in our training and validation data\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qyHrknvL0pOu"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AhtpmVue0p3G"
   },
   "source": [
    "We directly specify Keras symbols (Sequential, Dense, etc.) for the TensorFlow imports. This enables us to refer to these names directly in our code without qualifying their full names (for example, `Dense` instead of `tf.keras.layer.Dense`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rtPGh2MAVrVa"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GHHqtPisG3R1"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UZZI6lNkVrVm"
   },
   "source": [
    "# Data Loading - Dogs vs. Cats dataset from Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DPHx8-t-VrVo"
   },
   "source": [
    "To build our image classifier, we begin by downloading the dataset. The dataset we are using is a filtered version of <a href=\"https://www.kaggle.com/c/dogs-vs-cats/data\" target=\"_blank\">Dogs vs. Cats</a> dataset from Kaggle (ultimately, this dataset is provided by Microsoft Research).\n",
    "\n",
    "In previous Colabs, we've used <a href=\"https://www.tensorflow.org/datasets\" target=\"_blank\">TensorFlow Datasets</a>, which is a very easy and convenient way to use datasets. However, we will make use of the class `tf.keras.preprocessing.image.ImageDataGenerator`, which will read data from the disk. We, therefore, need to directly download *Dogs vs. Cats* from a URL and unzip it to the Colab filesystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "rpUSoFjuVrVp",
    "outputId": "3166375d-6f63-47e4-92bf-1aa0516f85a8"
   },
   "outputs": [],
   "source": [
    "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
    "zip_dir = tf.keras.utils.get_file('cats_and_dogs_filterted.zip', origin=_URL, extract=True, cache_dir=\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Giv0wMQzVrVw"
   },
   "source": [
    "The dataset we have downloaded has the following directory structure.\n",
    "\n",
    "<pre style=\"font-size: 10.0pt; font-family: Arial; line-height: 2; letter-spacing: 1.0pt;\" >\n",
    "<b>cats_and_dogs_filtered</b>\n",
    "|__ <b>train</b>\n",
    "    |______ <b>cats</b>: [cat.0.jpg, cat.1.jpg, cat.2.jpg ...]\n",
    "    |______ <b>dogs</b>: [dog.0.jpg, dog.1.jpg, dog.2.jpg ...]\n",
    "|__ <b>validation</b>\n",
    "    |______ <b>cats</b>: [cat.2000.jpg, cat.2001.jpg, cat.2002.jpg ...]\n",
    "    |______ <b>dogs</b>: [dog.2000.jpg, dog.2001.jpg, dog.2002.jpg ...]\n",
    "</pre>\n",
    "\n",
    "We can unzip the file and list the directories with the following terminal command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "colab_type": "code",
    "id": "ssD23VbTZeVA",
    "outputId": "9d5b6a4e-a486-4532-80ac-1d4002fc0854"
   },
   "outputs": [],
   "source": [
    "zip_dir_base = os.path.dirname(zip_dir)\n",
    "!find $zip_dir_base -type d -print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VpmywIlsVrVx"
   },
   "source": [
    "We'll now assign variables with the proper file path for the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sRucI3QqVrVy"
   },
   "outputs": [],
   "source": [
    "base_dir = os.path.join(os.path.dirname(zip_dir), 'cats_and_dogs_filtered')\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZdrHHTy2VrV3"
   },
   "source": [
    "### Understanding our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LblUYjl-VrV3"
   },
   "source": [
    "Let's look at how many cats and dogs images we have in our training and validation directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vc4u8e9hVrV4"
   },
   "outputs": [],
   "source": [
    "num_cats_tr = len(os.listdir(train_cats_dir))\n",
    "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
    "\n",
    "num_cats_val = len(os.listdir(validation_cats_dir))\n",
    "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
    "\n",
    "total_train = num_cats_tr + num_dogs_tr\n",
    "total_val = num_cats_val + num_dogs_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "id": "g4GGzGt0VrV7",
    "outputId": "264caa6b-3f65-42c6-c4f4-5d4290f1cac8"
   },
   "outputs": [],
   "source": [
    "print('total training cat images:', num_cats_tr)\n",
    "print('total training dog images:', num_dogs_tr)\n",
    "\n",
    "print('total validation cat images:', num_cats_val)\n",
    "print('total validation dog images:', num_dogs_val)\n",
    "print(\"--\")\n",
    "print(\"Total training images:\", total_train)\n",
    "print(\"Total validation images:\", total_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tdsI_L-NVrV_"
   },
   "source": [
    "# Setting Model Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Lp-0ejxOtP1"
   },
   "source": [
    "For convenience, we'll set up variables that will be used later while pre-processing our dataset and training our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3NqNselLVrWA"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100  # Number of training examples to process before updating our model's variables\n",
    "IMG_SHAPE  = 150  # Our training data consists of images with a width of 150 pixels and height of 150 pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "INn-cOn1VrWC"
   },
   "source": [
    "# Data Preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Jfk6aSAVrWD"
   },
   "source": [
    "Images must be formatted into appropriately pre-processed floating point tensors before being fed into the network. The steps involved in preparing these images are:\n",
    "\n",
    "1. Read images from the disk\n",
    "2. Decode the contents of these images and convert them into proper grid format as per their RGB content\n",
    "3. Convert them into floating point tensors\n",
    "4. Rescale the tensors from values between 0 and 255 to values between 0 and 1, as neural networks prefer to deal with small input values.\n",
    "\n",
    "Fortunately, all these tasks can be done using the class **tf.keras.preprocessing.image.ImageDataGenerator**.\n",
    "\n",
    "We can set this up in a couple of lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "syDdF_LWVrWE"
   },
   "outputs": [],
   "source": [
    "train_image_generator      = ImageDataGenerator(rescale=1./255)  # Generator for our training data\n",
    "validation_image_generator = ImageDataGenerator(rescale=1./255)  # Generator for our validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RLciCR_FVrWH"
   },
   "source": [
    "After defining our generators for training and validation images, **flow_from_directory** method will load images from the disk, apply rescaling, and resize them using a single line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Pw94ajOOVrWI",
    "outputId": "25583552-7bba-43c7-96f5-e5c16b7f6141"
   },
   "outputs": [],
   "source": [
    "train_data_gen = train_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n",
    "                                                           directory=train_dir,\n",
    "                                                           shuffle=True,\n",
    "                                                           target_size=(IMG_SHAPE,IMG_SHAPE), #(150,150)\n",
    "                                                           class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "2oUoKUzRVrWM",
    "outputId": "8c78e087-41c1-4c4a-f1e4-9f3b32752e76"
   },
   "outputs": [],
   "source": [
    "val_data_gen = validation_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n",
    "                                                              directory=validation_dir,\n",
    "                                                              shuffle=False,\n",
    "                                                              target_size=(IMG_SHAPE,IMG_SHAPE), #(150,150)\n",
    "                                                              class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hyexPJ8CVrWP"
   },
   "source": [
    "### Visualizing Training images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "60CnhEL4VrWQ"
   },
   "source": [
    "We can visualize our training images by getting a batch of images from the training generator and then plotting a few of them using `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3f0Z7NZgVrWQ"
   },
   "outputs": [],
   "source": [
    "sample_training_images, labels = next(train_data_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "49weMt5YVrWT"
   },
   "source": [
    "The `next` function returns a batch from the dataset. One batch is a tuple of (*many images*, *many labels*). Right now, we will look at 5 first images from `sample_training_images`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JMt2RES_VrWU"
   },
   "outputs": [],
   "source": [
    "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "d_VVg_gEVrWW",
    "outputId": "e56c82bb-e32d-4062-c4bb-208b95fc800c"
   },
   "outputs": [],
   "source": [
    "plotImages(sample_training_images[:5])  # Plot images 0-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can look at the labels to define the classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classes\n",
    "classes = [\"cat\", \"dog\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b5Ej-HLGVrWZ"
   },
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wEgW4i18VrWZ"
   },
   "source": [
    "## Define the model\n",
    "\n",
    "The model consists of four convolution blocks with a max pool layer in each. Then we have a fully connected layer with 512 units, with a `relu` activation function. The model will output class probabilities for two classes — dogs and cats — using `softmax`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F15-uwLPVrWa"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PI5cdkMQVrWc"
   },
   "source": [
    "### Compile the model\n",
    "\n",
    "As usual, we will use the `adam` optimizer. Since we output a softmax categorization, we'll use `sparse_categorical_crossentropy` as the loss function. We would also like to look at training and validation accuracy on each epoch as we train our network, so we are passing in the metrics argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Mg7_TXOVrWd"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2YmQZ3TAVrWg"
   },
   "source": [
    "### Model Summary\n",
    "\n",
    "Let's look at all the layers of our network using **summary** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 557
    },
    "colab_type": "code",
    "id": "Vtny8hmBVrWh",
    "outputId": "bfe5e6ba-4878-4d8e-ba1f-5937e2832c46"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N06iqE8VVrWj"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oub9RtoFVrWk"
   },
   "source": [
    "It's time we train our network.\n",
    "\n",
    "#### Attention: this will take time and use the power of your computer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "colab_type": "code",
    "id": "KSF2HqhDVrWk",
    "outputId": "d303ee71-28aa-4a57-b87a-7674dd80041c"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 100 # attention: this will take time and use the power of your computer!\n",
    "history = model.fit(\n",
    "    train_data_gen,\n",
    "    steps_per_epoch=int(np.ceil(total_train / float(BATCH_SIZE))),\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_data_gen,\n",
    "    validation_steps=int(np.ceil(total_val / float(BATCH_SIZE)))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the trained neural network (saving the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p saved_model\n",
    "model.save('saved_model/cats_dots_wo_data_aug')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ojJNteAGVrWo"
   },
   "source": [
    "### Visualizing results of the training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LZPYT-EmVrWo"
   },
   "source": [
    "We'll now visualize the results we get after training our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K6oA77ADVrWp"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(EPOCHS)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.savefig('./foo.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kDnr50l2VrWu"
   },
   "source": [
    "As we can see from the plots, training accuracy and validation accuracy are off by large margin and our model has achieved only around **70%** accuracy on the validation set (depending on the number of epochs you trained for).\n",
    "\n",
    "This is a clear indication of overfitting. Once the training and validation curves start to diverge, our model has started to memorize the training data and is unable to perform well on the validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading a previously saved model\n",
    "\n",
    "Only if you want to use the already trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('saved_model/cats_dots_wo_data_aug')\n",
    "\n",
    "# Check its architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making predictions based on the model and a picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the image you want to predict if it is a cat or dog\n",
    "When we use our model to make predictions on new images, it will also be useful to show the image. We can use the matplotlib library to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "def show_image(image_path):\n",
    "    image = mpimg.imread(image_path)\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_path = \"photo_cat2.jpg\"\n",
    "#img_path = 'photo-cute-dog.jpg'\n",
    "img_path = \"photo-white-cat.jpeg\"\n",
    "#img_path = \"fluffy-cat-breeds-american-bobtail.jpg\"\n",
    "\n",
    "show_image(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the Images\n",
    "\n",
    "The images in our dataset were 150x150 pixels. We need to make sure to pass the same size into our method for prediction. There are a few ways to edit images with Python, but Keras has a built-in utility that works well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image as image_utils\n",
    "\n",
    "def load_and_scale_image(image_path):\n",
    "    image = image_utils.load_img(image_path, target_size=(150,150))\n",
    "    image = image_utils.img_to_array(image)\n",
    "    image = np.array([image])  # Convert single image to a batch.\n",
    "    image = image / 255 # normalization to 8 bits\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_and_scale_image(img_path)\n",
    "plt.imshow(img[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing the Image for Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Make the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(img)\n",
    "# predictions = saved_model.predict(image) # Use this one if you are loading the saved model\n",
    "\n",
    "# Get the class with the highest probability\n",
    "class_index = np.argmax(predictions[0])\n",
    "\n",
    "# print the predicted class\n",
    "print(\"\\nThe model predicts that the image is a: {}\".format(classes[class_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Cats vs Dogs Without Data Augmentation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
